import trainomatic
import spacy
from collections import defaultdict
from itertools import product
from utils import read_probs
from numpy import log
import logging 
import pgf

# Generated by script in extract-ud2gf-cat-labels.py and data from the ud2gf UDTranslate.labels
POSSIBLE_GF_CATS_BY_UD_CAT = defaultdict(list, {'NOUN': ['N'],
                                 'PROPN': ['PN'],
                                 'ADJ': ['A', 'AdA'],
                                 'VERB': ['V', 'V2', 'V3', 'VV', 'VA', 'VS', 'VQ', 'V2V', 'V2A', 'V2S', 'V2Q'],
                                 'AUX': ['VV'],
                                 'ADV': ['AdA', 'AdN', 'AdV', 'Adv', 'IAdv', 'Subj'],
                                 'CONJ': ['Conj'],
                                 'PRON': ['Pron', 'NP', 'Det', 'IP'],
                                 'DET': ['Predet', 'Det', 'IDet', 'Quant', 'IQuant'],
                                 'INTJ': ['Interj'],
                                 'ADP': ['Prep'],
                                 'SCONJ': ['Subj']})

# TODO fix Pron

class Word:
    def __init__(self, lemma, UDPOS=''):
        self.is_root = lemma == 'ROOT'
        self.lemma = lemma
        self.UDPOS = UDPOS

    def possible_funs(self, possdict):
        if (self.is_root):
            return []
        poss = []
        for POS in POSSIBLE_GF_CATS_BY_UD_CAT[self.UDPOS]:
            poss.extend(possdict[(self.lemma, POS)])
        return poss        

    def __repr__(self):
        return self.lemma + '_' + self.UDPOS

    def __eq__(self, other):
        return self.__repr__() == other.__repr__()

    def __hash__(self):
        return hash(self.__repr__())

def get_bigrams_for_lemma(lemma, sentence, parser):
    bigrams = [(w,h) for w, h in get_bigrams(sentence, parser) 
               if w.lemma == lemma or h.lemma == lemma]
    return list(set(bigrams))


def get_bigrams(sentence, parser):
    tree = parser(sentence)
    return [(Word(w.lemma_, w.pos_), Word(w.head.lemma_, w.head.pos_) if w.dep_ != 'ROOT' else Word('ROOT')) 
            for w in tree]


def read_poss_dict(path='../data/gf_possibility_dictionaries/poss_dict_TranslateEng.pd'):
    with open(path, encoding='utf-8') as f:
        # format: 
        #    columnist \t N \t columnistFem_N \t columnistMasc_N
        lines = [l.strip().split('\t') for l in f]
        return defaultdict(lambda: [], {(l[0], l[1]): l[2:] for l in lines})


def possible_bigrams(bigrams, possdict):
    vocab = set()
    vocab.update(w for w, _ in bigrams if not w.is_root)
    vocab.update(h for _, h in bigrams if not h.is_root)
    reduced_dict = [[(w, poss) for poss in w.possible_funs(possdict)] for w in vocab if w.possible_funs(possdict)]
    permutations = product(*reduced_dict)
    for replacements in permutations:
        swapdict = dict(replacements) # swap word for abstract function
        swap = lambda w: swapdict[w] if w in vocab else w.lemma # Don't swap 'ROOT' etc
        yield [(swap(w), swap(h)) for w, h in bigrams]


# TODO make this nicer
def bigrams_prob(bigrams, probdict):
    prob = 0
    for bigram in bigrams:
        try:
            p = probdict[bigram]
            if not p == 0:
                prob += -log()
            else:
                raise Exception("Didn't find probability for bigram (%s, %s)" % bigram) 
        except KeyError:
            raise Exception("Didn't find probability for bigram (%s, %s)" % bigram)
    return prob

def read_wnid2fun(path):
    with open(path, encoding='utf-8') as f:
        for l in f:
            l_split = l.split()
            if len(l_split)==0 or l_split[0]!= 'fun':
                continue
            fun = l_split[1]
            l_splitbar = l.split('--')
            if len(l_splitbar)<2:
                continue
            try:
                wnid = int(l_splitbar[1].split()[0])
                yield wnid, fun
            except ValueError:
                continue

def test():
    logging.basicConfig(level=logging.INFO)
    logging.info('Loading Spacy')
    spacy_en = spacy.load('en_depent_web_md')
    logging.info('Loading Probabilities')
    probs = defaultdict(lambda: 0, read_probs('../results/test_total.probs'))
    logging.info('Loading GF')
    possdict = read_poss_dict(path='../data/gf_possibility_dictionaries/poss_dict_TranslateEng.pd')
    gr  = pgf.readPGF('../data/translate-pgfs/TranslateEng.pgf')
    lgr = gr.languages['TranslateEng']
    logging.info('Loading GF to wordnet')
    wn2fun = defaultdict(lambda: None, read_wnid2fun('../data/Dictionary.gf'))
    logging.info('Initialization finished')

    sentences = trainomatic.parse_dir()

    for wnid, sentence in sentences:
        fun = wn2fun[wnid] 
        if not fun:
            continue
        lemma = lgr.linearize(pgf.readExpr(fun))
        bigrams = get_bigrams_for_lemma(lemma, sentence, spacy_en)
        if not bigrams:
            continue
        for bigrams in possible_bigrams(bigrams, possdict):
            try:
                prob = bigrams_prob(bigrams, probs)
                print(bigrams)
                print('Prob: %d' % prob)
            except:
                pass

if __name__ == "__main__":
    #spacy_en = spacy.load('en_depent_web_md')
    test()
    pass
